# cp2024spb-rzd

[Преобразование каталога товаров ОАО «РЖД»](https://lk.hacks-ai.ru/event/1077380/case)

сабмит находится в /results/answer_dump.xlsx

1.	Ссылка на открытый репозиторий с исходным кодом https://github.com/gulldan/cp2024spb-rzd
2.	Ссылка на презентацию https://drive.google.com/file/d/13QVEvCmamU9xvgb_4q0YPfLK6ZtJtAxQ 
3.	Ссылка на прототип (ссылка на гит/ссылка на облако) - https://github.com/gulldan/cp2024spb-rzd 
4. Ссылка на информацию по кейсу https://lodmedia.hb.bizmrg.com/cases/1144863/%D0%A0%D0%96%D0%94_%D0%9A%D0%B0%D1%82%D0%B0%D0%BB%D0%BE%D0%B3.zip
5.	Ссылка на датасет https://lodmedia.hb.bizmrg.com/case_files/1144863/train_dataset_train%20%D1%80%D0%B6%D0%B4%20%D0%BA%D0%B0%D1%82%D0%B0%D0%BB%D0%BE%D0%B3.zip
6. Дополнительные фаилы https://drive.google.com/drive/folders/1lDGBOYgCMRmCBaYRJ2u174OfH3bjmC_P

# Технический отчет

**Пайплайн для обработки базы данных представлен в файле pipeline.py**

# Основная суть классов ClusterPipe и LLM

## Введение

Классы `ClusterPipe` и `LLM` предназначены для обработки и анализа текстовых данных с использованием вложений и языковых моделей. `ClusterPipe` занимается кластеризацией текстовых данных, а `LLM` используется для генерации текстовых ответов на основе языковой модели. Класс `PipelineManager` интегрирует оба класса для управления всем конвейером.

## Класс ClusterPipe

### Основная суть

Класс `ClusterPipe` предназначен для кластеризации текстовых данных с использованием вложений, сгенерированных из предобученной модели. Основные шаги включают:

1. **Инициализация**:
   - Загрузка путей к наборам данных MTR и labels, а также имя предобученной модели.
   - Инициализация токенизатора и модели.

2. **Загрузка данных**:
   - Загрузка данных из указанных путей.

3. **Подготовка текстов**:
   - Подготовка текстов для вложений путем добавления префикса.

4. **Генерация вложений**:
   - Генерация вложений для текстов пакетами.

5. **Сохранение и загрузка вложений**:
   - Сохранение и загрузка вложений в файл Parquet.

6. **Подготовка данных для кластеризации**:
   - Подготовка данных для кластеризации путем добавления столбцов "ОКПД2" и "код СКМТР".

7. **Кодирование меток**:
   - Кодирование столбца "ОКПД2" с использованием кодировщика меток.

8. **Заполнение пропущенных значений**:
   - Заполнение пропущенных значений с использованием KNNImputer.

9. **Кластеризация данных**:
   - Кластеризация данных для каждого уникального значения "ОКПД2" и сохранение сгруппированных данных в файл Parquet.

10. **Сохранение и загрузка сгруппированных данных**:
    - Сохранение и загрузка сгруппированных данных в файл Parquet.

11. **Фильтрация кластеров**:
    - Фильтрация сгруппированных данных для возврата DataFrame, содержащего только строки, принадлежащие определенному кластеру и идентификатору OKPD2.

## Класс LLM

### Основная суть

Класс `LLM` используется для генерации текстовых ответов на основе языковой модели. Основные шаги включают:

1. **Инициализация**:
   - Загрузка имени модели и инициализация токенизатора и модели.

2. **Подготовка промпта**:
   - Подготовка промпта в формате, требуемом моделью.

3. **Генерация ответа**:
   - Генерация ответа от модели LLM на основе заданного промпта.

4. **Обработка сообщения**:
   - Обработка сообщения для генерации ответа от модели LLM.

## Класс PipelineManager

### Основная суть

Класс `PipelineManager` интегрирует функциональность классов `ClusterPipe` и `LLM` для управления всем конвейером. Основные шаги включают:

1. **Инициализация**:
   - Создание экземпляра класса `PipelineManager`, указав экземпляры `ClusterPipe` и `LLM`.

2. **Получение кластера**:
   - Получение кластера по номеру кластера и идентификатору OKPD2.

3. **Получение названия кластера**:
   - Генерация названия кластера с использованием модели LLM.

4. **Обработка кластера**:
   - Обработка кластера для генерации названия кластера, свойств и парсинга свойств товаров.

5. **Обработка OKPD**:
   - Обработка всех кластеров для заданного идентификатора OKPD2.

## Заключение

Классы `ClusterPipe` и `LLM` предоставляют мощные инструменты для кластеризации текстовых данных и генерации текстовых ответов. Класс `PipelineManager` интегрирует их функциональность для создания полного конвейера обработки данных. Эти классы могут быть использованы для различных задач, связанных с анализом текстовых данных и генерацией текстовых ответов.

# Parser

## **Пошаговый алгоритм работы парсера**

1. **Инициализация**:

   - Настраивается логирование для отслеживания процесса выполнения скрипта.
   - Определяются глобальные переменные и списки URL сайтов для поиска.

2. **Чтение данных**:

   - Загружается файл `MTR.parquet` с помощью Polars.
   - Отфильтровываются записи, где поле `'Параметры'` пустое.

3. **Цикл обработки товаров**:

   - Для каждого товара из отфильтрованного списка:
     - Проверяется наличие выходного файла в папке `output`. Если файл уже существует, товар пропускается.
     - Извлекаются `'Наименование'`, `'Маркировка'` и `'код СКМТР'`.
     - Формируется поисковый запрос на основе длины полей `'Наименование'` и `'Маркировка'`.
     - Если поисковый запрос пустой, создается пустой JSON-файл, и скрипт переходит к следующему товару.

4. **Выполнение поиска и сбор ссылок**:

   - Инициализируется браузер с помощью Playwright и настраивается stealth-режим.
   - Выполняется поиск в Google с использованием поискового запроса и ограничением по сайтам.
   - Если результатов нет, выполняется повторный поиск без ограничения по сайтам.
   - Собираются ссылки на первые `n` результатов (по умолчанию 7).

5. **Обработка ссылок**:

   - Каждая ссылка обрабатывается асинхронно:
     - Переход по ссылке с учетом таймаутов.
     - Эмуляция пользовательского взаимодействия для обхода возможных защит на сайте.
     - Извлечение характеристик товара с помощью парсинга контента страницы.
     - Сохранение результатов во временный JSON-файл с именем, включающим `'код СКМТР'` и индекс ссылки.

6. **Объединение результатов**:

   - После обработки всех ссылок характеристики объединяются в один словарь.
   - Используется функция похожести строк из библиотеки rapidfuzz для объединения характеристик с похожими названиями.

7. **Сохранение окончательных данных**:

   - Объединенные характеристики сохраняются в файл JSON в папке `output`, имя файла соответствует `'код СКМТР'`.
   - Если характеристики не найдены, создается пустой JSON-файл.

8. **Очистка и завершение**:

   - Удаляются временные файлы, созданные при обработке ссылок.
   - Закрывается браузер и освобождаются ресурсы.

Более подробная информация лежт в папке parser README.md
